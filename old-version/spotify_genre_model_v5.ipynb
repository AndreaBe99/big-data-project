{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pyspark\n!pip install findspark\n# Alternatively, if you want to install a specific version of pyspark:\n#!pip install pyspark==3.2.1 ","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:56:15.704941Z","iopub.execute_input":"2022-05-13T14:56:15.705931Z","iopub.status.idle":"2022-05-13T14:57:18.418589Z","shell.execute_reply.started":"2022-05-13T14:56:15.705776Z","shell.execute_reply":"2022-05-13T14:57:18.417740Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\nimport requests\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport pyspark\nfrom pyspark.sql import *\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import *\nfrom pyspark import SparkContext, SparkConf\nimport pyspark.sql.functions as f\nfrom pyspark.sql.functions import split, regexp_replace, year, month, dayofmonth, to_timestamp\n\nfrom pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\nfrom pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, RandomForestClassifier\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator #, BinaryClassificationEvaluator \n\n# Basic libreries \nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Pre-processing phase\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split\n\n# Features Importance\nfrom sklearn.inspection import permutation_importance\n\n# Model\nfrom sklearn import tree\nfrom sklearn import svm\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neural_network import MLPClassifier\n\n# Hyper-Parameter Tuning\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\n\nfrom sklearn.model_selection import cross_val_score\n\n# Evaluation\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:57:18.421293Z","iopub.execute_input":"2022-05-13T14:57:18.422074Z","iopub.status.idle":"2022-05-13T14:57:20.119445Z","shell.execute_reply.started":"2022-05-13T14:57:18.422015Z","shell.execute_reply":"2022-05-13T14:57:20.118799Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# create the session\nconf = SparkConf().set(\"spark.ui.port\", \"4050\").set('spark.executor.memory', '10G').set('spark.driver.memory', '45G').set('spark.driver.maxResultSize', '20G').set(\"spark.sql.autoBroadcastJoinThreshold\", -1)\n\n# create the context\nsc = pyspark.SparkContext(conf=conf)\nspark = SparkSession.builder.getOrCreate()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:57:20.121116Z","iopub.execute_input":"2022-05-13T14:57:20.121664Z","iopub.status.idle":"2022-05-13T14:57:25.552760Z","shell.execute_reply.started":"2022-05-13T14:57:20.121621Z","shell.execute_reply":"2022-05-13T14:57:25.552029Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"spark","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:57:25.554813Z","iopub.execute_input":"2022-05-13T14:57:25.555167Z","iopub.status.idle":"2022-05-13T14:57:26.586586Z","shell.execute_reply.started":"2022-05-13T14:57:25.555117Z","shell.execute_reply":"2022-05-13T14:57:26.585993Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"sc._conf.getAll()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:57:26.587473Z","iopub.execute_input":"2022-05-13T14:57:26.587672Z","iopub.status.idle":"2022-05-13T14:57:26.611466Z","shell.execute_reply.started":"2022-05-13T14:57:26.587646Z","shell.execute_reply":"2022-05-13T14:57:26.610882Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"spotify_tracks = spark.read.load(\"../input/spotify-track/dataframe.csv\", \n                           format=\"csv\", \n                           sep=\";\", \n                           inferSchema=\"true\", \n                           header=\"true\")\n","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:57:26.612613Z","iopub.execute_input":"2022-05-13T14:57:26.614279Z","iopub.status.idle":"2022-05-13T14:57:33.721130Z","shell.execute_reply.started":"2022-05-13T14:57:26.614228Z","shell.execute_reply":"2022-05-13T14:57:33.720141Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")\nspotify_tracks.cache()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:57:33.722308Z","iopub.execute_input":"2022-05-13T14:57:33.722542Z","iopub.status.idle":"2022-05-13T14:57:33.857077Z","shell.execute_reply.started":"2022-05-13T14:57:33.722511Z","shell.execute_reply":"2022-05-13T14:57:33.856150Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"print(\"The shape of the dataset is {:d} rows by {:d} columns\".format(spotify_tracks.count(), len(spotify_tracks.columns)))","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:57:33.858720Z","iopub.execute_input":"2022-05-13T14:57:33.859224Z","iopub.status.idle":"2022-05-13T14:57:37.029604Z","shell.execute_reply.started":"2022-05-13T14:57:33.859176Z","shell.execute_reply":"2022-05-13T14:57:37.028395Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"spotify_tracks.printSchema()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:57:37.031195Z","iopub.execute_input":"2022-05-13T14:57:37.031963Z","iopub.status.idle":"2022-05-13T14:57:37.042770Z","shell.execute_reply.started":"2022-05-13T14:57:37.031849Z","shell.execute_reply":"2022-05-13T14:57:37.041930Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"spotify_tracks.show(5)","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:57:37.047209Z","iopub.execute_input":"2022-05-13T14:57:37.047992Z","iopub.status.idle":"2022-05-13T14:57:38.442684Z","shell.execute_reply.started":"2022-05-13T14:57:37.047940Z","shell.execute_reply":"2022-05-13T14:57:38.441635Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"spotify_tracks = spotify_tracks.dropDuplicates()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:57:38.445888Z","iopub.execute_input":"2022-05-13T14:57:38.446285Z","iopub.status.idle":"2022-05-13T14:57:38.466411Z","shell.execute_reply.started":"2022-05-13T14:57:38.446234Z","shell.execute_reply":"2022-05-13T14:57:38.465209Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"spotify_tracks = spotify_tracks.select(spotify_tracks.columns + [f.translate(f.col(\"audio_avg_pitches\"), \"[]\", \"\").alias(\"audio_avg_pitches_list\")])\nspotify_tracks = spotify_tracks.withColumn(\"pitch_1\", split(col(\"audio_avg_pitches_list\"), \", \").getItem(0))\\\n                                .withColumn(\"pitch_2\", split(col(\"audio_avg_pitches_list\"), \", \").getItem(1))\\\n                                .withColumn(\"pitch_3\", split(col(\"audio_avg_pitches_list\"), \", \").getItem(2))\\\n                                .withColumn(\"pitch_4\", split(col(\"audio_avg_pitches_list\"), \", \").getItem(3))\\\n                                .withColumn(\"pitch_5\", split(col(\"audio_avg_pitches_list\"), \", \").getItem(4))\\\n                                .withColumn(\"pitch_6\", split(col(\"audio_avg_pitches_list\"), \", \").getItem(5))\\\n                                .withColumn(\"pitch_7\", split(col(\"audio_avg_pitches_list\"), \", \").getItem(6))\\\n                                .withColumn(\"pitch_8\", split(col(\"audio_avg_pitches_list\"), \", \").getItem(7))\\\n                                .withColumn(\"pitch_9\", split(col(\"audio_avg_pitches_list\"), \", \").getItem(8))\\\n                                .withColumn(\"pitch_10\", split(col(\"audio_avg_pitches_list\"), \", \").getItem(9))\\\n                                .withColumn(\"pitch_11\", split(col(\"audio_avg_pitches_list\"), \", \").getItem(10))\\\n                                .withColumn(\"pitch_12\", split(col(\"audio_avg_pitches_list\"), \", \").getItem(11))\nspotify_tracks.printSchema()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:57:38.467671Z","iopub.execute_input":"2022-05-13T14:57:38.472335Z","iopub.status.idle":"2022-05-13T14:57:39.009980Z","shell.execute_reply.started":"2022-05-13T14:57:38.472263Z","shell.execute_reply":"2022-05-13T14:57:39.008963Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"spotify_tracks = spotify_tracks.select(spotify_tracks.columns + [f.translate(f.col(\"audio_avg_timbre\"), \"[]\", \"\").alias(\"audio_avg_timbre_list\")])\nspotify_tracks = spotify_tracks.withColumn(\"timbre_1\", split(col(\"audio_avg_timbre_list\"), \", \").getItem(0))\\\n                                .withColumn(\"timbre_2\", split(col(\"audio_avg_timbre_list\"), \", \").getItem(1))\\\n                                .withColumn(\"timbre_3\", split(col(\"audio_avg_timbre_list\"), \", \").getItem(2))\\\n                                .withColumn(\"timbre_4\", split(col(\"audio_avg_timbre_list\"), \", \").getItem(3))\\\n                                .withColumn(\"timbre_5\", split(col(\"audio_avg_timbre_list\"), \", \").getItem(4))\\\n                                .withColumn(\"timbre_6\", split(col(\"audio_avg_timbre_list\"), \", \").getItem(5))\\\n                                .withColumn(\"timbre_7\", split(col(\"audio_avg_timbre_list\"), \", \").getItem(6))\\\n                                .withColumn(\"timbre_8\", split(col(\"audio_avg_timbre_list\"), \", \").getItem(7))\\\n                                .withColumn(\"timbre_9\", split(col(\"audio_avg_timbre_list\"), \", \").getItem(8))\\\n                                .withColumn(\"timbre_10\", split(col(\"audio_avg_timbre_list\"), \", \").getItem(9))\\\n                                .withColumn(\"timbre_11\", split(col(\"audio_avg_timbre_list\"), \", \").getItem(10))\\\n                                .withColumn(\"timbre_12\", split(col(\"audio_avg_timbre_list\"), \", \").getItem(11))\nspotify_tracks.printSchema()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:57:39.011292Z","iopub.execute_input":"2022-05-13T14:57:39.012802Z","iopub.status.idle":"2022-05-13T14:57:39.597438Z","shell.execute_reply.started":"2022-05-13T14:57:39.012755Z","shell.execute_reply":"2022-05-13T14:57:39.596459Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# String to Date but return null value \n# spotify_tracks_dt = spotify_tracks.withColumn(\"album_release_date\", to_date(col(\"album_release_date\"),\"yyyy-MM-dd\"))\n# spotify_tracks_dt.select(\"album_release_date\").show()\n\ndef to_date_(col, formats=(\"yyyy-MM-dd\", \"y\")):\n    # Spark 2.2 or later syntax, for < 2.2 use unix_timestamp and cast\n    return coalesce(*[to_date(col, f) for f in formats])\n\nspotify_tracks = spotify_tracks.withColumn(\"album_release_date_td\", to_date_(\"album_release_date\"))\nspotify_tracks.select(\"album_release_date_td\").show()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:57:39.598713Z","iopub.execute_input":"2022-05-13T14:57:39.599012Z","iopub.status.idle":"2022-05-13T14:57:42.652761Z","shell.execute_reply.started":"2022-05-13T14:57:39.598970Z","shell.execute_reply":"2022-05-13T14:57:42.651874Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"spotify_tracks = spotify_tracks.withColumn('day', dayofmonth(col('album_release_date_td')))\nspotify_tracks = spotify_tracks.withColumn('month', month(col('album_release_date_td')))\nspotify_tracks = spotify_tracks.withColumn('year', year(col('album_release_date_td')))","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:57:42.653978Z","iopub.execute_input":"2022-05-13T14:57:42.654282Z","iopub.status.idle":"2022-05-13T14:57:42.743535Z","shell.execute_reply.started":"2022-05-13T14:57:42.654242Z","shell.execute_reply":"2022-05-13T14:57:42.742501Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"spotify_tracks.printSchema()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:57:42.744819Z","iopub.execute_input":"2022-05-13T14:57:42.745248Z","iopub.status.idle":"2022-05-13T14:57:42.753788Z","shell.execute_reply.started":"2022-05-13T14:57:42.745203Z","shell.execute_reply":"2022-05-13T14:57:42.752844Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"cols = (\"album_release_date\", \"album_release_date_td\", \"audio_avg_pitches\",\"audio_avg_timbre\", \"audio_avg_pitches_list\", \"audio_avg_timbre_list\", \"track_uri\", \"id\")\nspotify_tracks = spotify_tracks.drop(*cols)\n\nspotify_tracks.printSchema()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:57:42.755660Z","iopub.execute_input":"2022-05-13T14:57:42.756220Z","iopub.status.idle":"2022-05-13T14:57:42.786757Z","shell.execute_reply.started":"2022-05-13T14:57:42.756176Z","shell.execute_reply":"2022-05-13T14:57:42.785817Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"spotify_tracks = spotify_tracks.withColumn(\"pitch_1\", spotify_tracks.pitch_1.cast('double'))\\\n                                .withColumn(\"pitch_2\", spotify_tracks.pitch_2.cast('double'))\\\n                                .withColumn(\"pitch_3\", spotify_tracks.pitch_3.cast('double'))\\\n                                .withColumn(\"pitch_4\", spotify_tracks.pitch_4.cast('double'))\\\n                                .withColumn(\"pitch_5\", spotify_tracks.pitch_5.cast('double'))\\\n                                .withColumn(\"pitch_6\", spotify_tracks.pitch_6.cast('double'))\\\n                                .withColumn(\"pitch_7\", spotify_tracks.pitch_7.cast('double'))\\\n                                .withColumn(\"pitch_8\", spotify_tracks.pitch_8.cast('double'))\\\n                                .withColumn(\"pitch_9\", spotify_tracks.pitch_9.cast('double'))\\\n                                .withColumn(\"pitch_10\", spotify_tracks.pitch_10.cast('double'))\\\n                                .withColumn(\"pitch_11\", spotify_tracks.pitch_11.cast('double'))\\\n                                .withColumn(\"pitch_12\", spotify_tracks.pitch_12.cast('double'))\n\nspotify_tracks = spotify_tracks.withColumn(\"timbre_1\", spotify_tracks.timbre_1.cast('double'))\\\n                                .withColumn(\"timbre_2\", spotify_tracks.timbre_2.cast('double'))\\\n                                .withColumn(\"timbre_3\", spotify_tracks.timbre_3.cast('double'))\\\n                                .withColumn(\"timbre_4\", spotify_tracks.timbre_4.cast('double'))\\\n                                .withColumn(\"timbre_5\", spotify_tracks.timbre_5.cast('double'))\\\n                                .withColumn(\"timbre_6\", spotify_tracks.timbre_6.cast('double'))\\\n                                .withColumn(\"timbre_7\", spotify_tracks.timbre_7.cast('double'))\\\n                                .withColumn(\"timbre_8\", spotify_tracks.timbre_8.cast('double'))\\\n                                .withColumn(\"timbre_9\", spotify_tracks.timbre_9.cast('double'))\\\n                                .withColumn(\"timbre_10\", spotify_tracks.timbre_10.cast('double'))\\\n                                .withColumn(\"timbre_11\", spotify_tracks.timbre_11.cast('double'))\\\n                                .withColumn(\"timbre_12\", spotify_tracks.timbre_12.cast('double'))\n\nspotify_tracks = spotify_tracks.withColumn(\"year\", spotify_tracks.year.cast('int'))\\\n                                .withColumn(\"day\", spotify_tracks.day.cast('int'))\\\n                                .withColumn(\"month\", spotify_tracks.month.cast('int'))\n\nspotify_tracks.printSchema()\n","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:57:42.788108Z","iopub.execute_input":"2022-05-13T14:57:42.788398Z","iopub.status.idle":"2022-05-13T14:57:43.264543Z","shell.execute_reply.started":"2022-05-13T14:57:42.788356Z","shell.execute_reply":"2022-05-13T14:57:43.263584Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Let's define some constants which we will use throughout this notebook\nNUMERICAL_FEATURES = []\nCATEGORICAL_FEATURES = []\nTARGET_VARIABLE = \"track_genre\"\n\n#Get All column names and it's types\nfor col in spotify_tracks.dtypes:\n    if col[1] == \"string\":\n        CATEGORICAL_FEATURES.append(col[0])\n    else:\n        NUMERICAL_FEATURES.append(col[0])\n\nCATEGORICAL_FEATURES.remove(TARGET_VARIABLE)\nprint(\"Categorical: \", CATEGORICAL_FEATURES, \"\\nNumerical: \", NUMERICAL_FEATURES)","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:57:43.265687Z","iopub.execute_input":"2022-05-13T14:57:43.265961Z","iopub.status.idle":"2022-05-13T14:57:43.278903Z","shell.execute_reply.started":"2022-05-13T14:57:43.265924Z","shell.execute_reply":"2022-05-13T14:57:43.278107Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"spotify_tracks.cache()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:57:43.280604Z","iopub.execute_input":"2022-05-13T14:57:43.281206Z","iopub.status.idle":"2022-05-13T14:57:43.519173Z","shell.execute_reply.started":"2022-05-13T14:57:43.281162Z","shell.execute_reply":"2022-05-13T14:57:43.518224Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"#spotify_tracks_rp = spark.createDataFrame(spotify_tracks_pd)\n\nspotify_tracks.rdd.getNumPartitions()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:57:43.522170Z","iopub.execute_input":"2022-05-13T14:57:43.522869Z","iopub.status.idle":"2022-05-13T14:57:43.848629Z","shell.execute_reply.started":"2022-05-13T14:57:43.522810Z","shell.execute_reply":"2022-05-13T14:57:43.847935Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"#spotify_tracks = spotify_tracks.repartition(1000)\nspotify_tracks = spotify_tracks.coalesce(100)\nspotify_tracks.rdd.getNumPartitions()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:57:43.849745Z","iopub.execute_input":"2022-05-13T14:57:43.850080Z","iopub.status.idle":"2022-05-13T14:57:43.970388Z","shell.execute_reply.started":"2022-05-13T14:57:43.850021Z","shell.execute_reply":"2022-05-13T14:57:43.969540Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# null values in each column\ndata_agg = spotify_tracks.agg(*[f.count(f.when(f.isnull(c), c)).alias(c) for c in spotify_tracks.columns])\n\ndata_agg.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:57:43.975330Z","iopub.execute_input":"2022-05-13T14:57:43.975953Z","iopub.status.idle":"2022-05-13T14:58:04.618268Z","shell.execute_reply.started":"2022-05-13T14:57:43.975905Z","shell.execute_reply":"2022-05-13T14:58:04.617312Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"spotify_tracks = spotify_tracks.dropna()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:58:04.619435Z","iopub.execute_input":"2022-05-13T14:58:04.619725Z","iopub.status.idle":"2022-05-13T14:58:04.662292Z","shell.execute_reply.started":"2022-05-13T14:58:04.619687Z","shell.execute_reply":"2022-05-13T14:58:04.661233Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"data_agg = spotify_tracks.agg(*[f.count(f.when(f.isnull(c), c)).alias(c) for c in spotify_tracks.columns])\n\ndata_agg.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:58:04.663543Z","iopub.execute_input":"2022-05-13T14:58:04.663823Z","iopub.status.idle":"2022-05-13T14:58:06.844495Z","shell.execute_reply.started":"2022-05-13T14:58:04.663784Z","shell.execute_reply":"2022-05-13T14:58:06.843642Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# value counts of Batsman_Name column\nspotify_tracks.groupBy('album_release_date_precision').count().show()\n\nspotify_tracks.groupBy('track_name').count().show()\n\nspotify_tracks.groupBy('album_name').count().show()\n\nspotify_tracks.groupBy('artist_name').count().show()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:58:06.845723Z","iopub.execute_input":"2022-05-13T14:58:06.846051Z","iopub.status.idle":"2022-05-13T14:58:19.290328Z","shell.execute_reply.started":"2022-05-13T14:58:06.845996Z","shell.execute_reply":"2022-05-13T14:58:19.289450Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# This function is responsible to implement the pipeline above for transforming categorical features into numerical ones\ndef to_numerical(df, numerical_features, categorical_features, target_variable):\n  \n    # 1. Label Encode target feature \n    label_indexer= StringIndexer(inputCol=target_variable, outputCol='label')\n\n    # 2. Label Encode Categorical features\n    indexer = [StringIndexer(inputCol=c, outputCol=\"{0}_index\".format(c), handleInvalid=\"skip\") for c in categorical_features]\n\n    # 3. OneHot Encode \n    # stage_3 = OneHotEncoder(inputCol='album_release_date_precision_index', outputCol='album_release_date_precision_oh')\n\n    # 4. create a vector of all the features required to train the logistic regression model \n    # encoded_columns = ['track_name_index', 'album_name_index', 'artist_name_index', 'album_release_date_precision_oh']\n    # stage_4 = VectorAssembler(inputCols= encoded_columns + numerical_features, outputCol='features')\n    assembler = VectorAssembler(inputCols= [indexer.getOutputCol() for indexer in indexer] + numerical_features, outputCol='features')\n    \n    # 4.a Create the StandardScaler\n    scaler = StandardScaler(inputCol=assembler.getOutputCol(), outputCol=\"std_\" + assembler.getOutputCol(), withStd=True, withMean=True)\n\n   \n\n    # 5. Populate the stages of the pipeline\n    # stages = [stage_1] + stage_2 +[stage_3] + [stage_4] + [scaler]\n    stages = [label_indexer] + indexer + [assembler] + [scaler]\n    # 6. Setup the pipeline with the stages above\n    pipeline = Pipeline(stages=stages)\n\n    # 7. Transform the input dataframe accordingly\n    transformer = pipeline.fit(df)\n    df_transformed = transformer.transform(df)\n\n    return df_transformed","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:58:19.291612Z","iopub.execute_input":"2022-05-13T14:58:19.291933Z","iopub.status.idle":"2022-05-13T14:58:19.302242Z","shell.execute_reply.started":"2022-05-13T14:58:19.291888Z","shell.execute_reply":"2022-05-13T14:58:19.301390Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# Transform the training set and get back both the transformer and the new dataset\nspotify_tracks_encoded = to_numerical(spotify_tracks, NUMERICAL_FEATURES, CATEGORICAL_FEATURES, TARGET_VARIABLE)\nspotify_tracks_encoded.cache()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:58:19.307559Z","iopub.execute_input":"2022-05-13T14:58:19.308135Z","iopub.status.idle":"2022-05-13T14:58:45.474562Z","shell.execute_reply.started":"2022-05-13T14:58:19.308096Z","shell.execute_reply":"2022-05-13T14:58:45.473555Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Clean-up unused variables\n# Let's try to free-up some RAM\nimport gc\ndel spotify_tracks\n# ...\n\nprint(\"Garbage collector: collected %d objects\" % (gc.collect()))","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:58:45.476813Z","iopub.execute_input":"2022-05-13T14:58:45.477156Z","iopub.status.idle":"2022-05-13T14:58:45.721627Z","shell.execute_reply.started":"2022-05-13T14:58:45.477092Z","shell.execute_reply":"2022-05-13T14:58:45.720663Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# Check and remove any possible zero-length vector\n@udf(\"long\")\ndef num_nonzeros(v):\n    return v.numNonzeros()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:58:45.723479Z","iopub.execute_input":"2022-05-13T14:58:45.723812Z","iopub.status.idle":"2022-05-13T14:58:45.762042Z","shell.execute_reply.started":"2022-05-13T14:58:45.723756Z","shell.execute_reply":"2022-05-13T14:58:45.761341Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Check if there is any zero-lenght vector\nprint(\"Total n. of zero-length vectors: {:d}\".\n      format(spotify_tracks_encoded.where(num_nonzeros(\"std_features\") == 0).count()))","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:58:45.763240Z","iopub.execute_input":"2022-05-13T14:58:45.764033Z","iopub.status.idle":"2022-05-13T14:58:57.632815Z","shell.execute_reply.started":"2022-05-13T14:58:45.763998Z","shell.execute_reply":"2022-05-13T14:58:57.631814Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# Remove zero-lenght vector(s)\nspotify_tracks_encoded = spotify_tracks_encoded.where(num_nonzeros(\"std_features\") > 0)","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:58:57.634144Z","iopub.execute_input":"2022-05-13T14:58:57.634448Z","iopub.status.idle":"2022-05-13T14:58:57.701184Z","shell.execute_reply.started":"2022-05-13T14:58:57.634410Z","shell.execute_reply":"2022-05-13T14:58:57.700219Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# Double-check there is no more zero-length vector\nprint(\"Total n. of zero-length vectors (after removal): {:d}\".\n      format(spotify_tracks_encoded.where(num_nonzeros(\"features\") == 0).count()))\nprint(\"Garbage collector: collected %d objects\" % (gc.collect()))","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:58:57.702422Z","iopub.execute_input":"2022-05-13T14:58:57.702682Z","iopub.status.idle":"2022-05-13T14:59:05.909115Z","shell.execute_reply.started":"2022-05-13T14:58:57.702643Z","shell.execute_reply":"2022-05-13T14:59:05.906850Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# Select `features` and `label` (i.e., formerly `deposit`) target variable only\nspotify_tracks_final = spotify_tracks_encoded.select([\"std_features\", \"label\"])\nspotify_tracks_final.cache()\n\nRANDOM_SEED = 42\n# Randomly split our original dataset `house_df` into 80รท20 for training and test, respectively\ntrain_set, test_set = spotify_tracks_final.randomSplit([0.8, 0.2], seed=RANDOM_SEED)\n\ntrain_set.show(5, truncate=False)\ntrain_set.printSchema()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:59:05.910957Z","iopub.execute_input":"2022-05-13T14:59:05.911279Z","iopub.status.idle":"2022-05-13T14:59:06.758990Z","shell.execute_reply.started":"2022-05-13T14:59:05.911237Z","shell.execute_reply":"2022-05-13T14:59:06.758118Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"del spotify_tracks_final\n# ...\n\nprint(\"Garbage collector: collected %d objects\" % (gc.collect()))","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:59:06.760243Z","iopub.execute_input":"2022-05-13T14:59:06.760546Z","iopub.status.idle":"2022-05-13T14:59:06.944200Z","shell.execute_reply.started":"2022-05-13T14:59:06.760505Z","shell.execute_reply":"2022-05-13T14:59:06.943156Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"#train_set.select(col(\"std_features\")).show(10, truncate=False)\n\n# PROVA \n#LR = LogisticRegression(featuresCol = 'std_features', labelCol = 'label', maxIter=15)\n#LR_model = LR.fit(train_set)","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:59:06.945720Z","iopub.execute_input":"2022-05-13T14:59:06.946752Z","iopub.status.idle":"2022-05-13T14:59:06.953539Z","shell.execute_reply.started":"2022-05-13T14:59:06.946695Z","shell.execute_reply":"2022-05-13T14:59:06.952166Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"stage_5_lg = LogisticRegression(featuresCol='std_features',labelCol='label')\n\nlogistic_regression_pipeline = Pipeline(stages= [stage_5_lg])\n\npipelineModel = logistic_regression_pipeline.fit(train_set)\n\npredictions_test = pipelineModel.transform(test_set)\n\nevaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\naccuracy = evaluator.evaluate(predictions_test)\nprint('Test F1-Score ',   evaluator.evaluate(predictions_test, \n                                  {evaluator.metricName: 'f1'}))\nprint('Test Precision ',  evaluator.evaluate(predictions_test,\n                                    {evaluator.metricName: 'weightedPrecision'}))\nprint('Test Recall ',     evaluator.evaluate(predictions_test, \n                                    {evaluator.metricName: 'weightedRecall'}))\nprint('Test Accuracy ',   evaluator.evaluate(predictions_test, \n                                  {evaluator.metricName: 'accuracy'}))","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:59:06.955010Z","iopub.execute_input":"2022-05-13T14:59:06.955592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This function defines the general pipeline for logistic regression\ndef decision_tree_pipeline(train):\n  \n    stage_5_dr = DecisionTreeClassifier(featuresCol='std_features',labelCol='label')\n\n    decision_tree_pipeline = Pipeline(stages= [stage_5_dr])\n\n    #### DECISION TREE\n    param_grid = ParamGridBuilder()\\\n    .addGrid(stage_5_dr.maxDepth, [3, 5]) \\\n    .addGrid(stage_5_dr.impurity, [\"gini\", \"entropy\"]) \\\n    .build()\n    cross_val_dt = CrossValidator(estimator=decision_tree_pipeline,\n                                    estimatorParamMaps=param_grid,\n                                    evaluator=MulticlassClassificationEvaluator().setMetricName(\"accuracy\"), # default = \"areaUnderROC\", alternatively \"areaUnderPR\"\n                                    numFolds=5,\n                                    collectSubModels=False\n                                    )\n    print(\"Garbage collector: collected %d objects\" % (gc.collect()))\n    cv_model_dt = cross_val_dt.fit(train)\n\n    return cv_model_dt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This function defines the general pipeline for logistic regression\ndef logistic_regression_pipeline(train):\n  \n    stage_5_lg = LogisticRegression(featuresCol='std_features',labelCol='label')\n\n    logistic_regression_pipeline = Pipeline(stages= [stage_5_lg])\n\n    #### LOGISTIC REGRESSION\n    param_grid = ParamGridBuilder()\\\n    .addGrid(stage_5_lg.regParam, [0.01, 0.1, 1.0]) \\\n    .addGrid(stage_5_lg.maxIter, [10, 20, 50]) \\\n    .build()\n    # other param: .addGrid(stage_4_lg.elasticNetParam, [0.0, 0.25, 0.5, 0.75, 1.0])\n    cross_val_lg = CrossValidator(estimator=logistic_regression_pipeline,\n                            estimatorParamMaps=param_grid,\n                            evaluator=MulticlassClassificationEvaluator().setMetricName(\"accuracy\"), # default = \"areaUnderROC\", alternatively \"areaUnderPR\"\n                            numFolds=5,\n                            collectSubModels=True\n                            )\n    print(\"Garbage collector: collected %d objects\" % (gc.collect()))\n    cv_model_lg = cross_val_lg.fit(train)\n\n    return cv_model_lg","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This function defines the general pipeline for logistic regression\ndef random_forest_pipeline(train):\n  \n    stage_5_rf = RandomForestClassifier(featuresCol=\"std_features\", labelCol=\"label\")\n\n    random_forest_pipeline = Pipeline(stages= [stage_5_rf])\n\n    #### RANDOM FOREST\n    param_grid = ParamGridBuilder()\\\n    .addGrid(stage_5_rf.maxDepth, [3, 5, 8]) \\\n    .addGrid(stage_5_rf.numTrees, [10, 50, 100]) \\\n    .build()\n    cross_val_rf = CrossValidator(estimator=random_forest_pipeline, \n                          estimatorParamMaps=param_grid,\n                          evaluator= MulticlassClassificationEvaluator().setMetricName(\"accuracy\"), # default = \"areaUnderROC\", alternatively \"areaUnderPR\"\n                          numFolds=5,\n                          collectSubModels=False \n                          )\n    print(\"Garbage collector: collected %d objects\" % (gc.collect()))\n    cv_model_rf = cross_val_rf.fit(train)\n\n    return cv_model_rf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv_model_dt = decision_tree_pipeline(train_set)\n\n# Make predictions on the test set (`cv_model` contains the best model according to the result of k-fold cross validation)\n# `test_df` will follow exactly the same pipeline defined above, and already fit to `train_df`\ntest_predictions_dt = cv_model_dt.transform(test_set)\n\ntest_predictions_dt.select(\"std_features\", \"prediction\", \"label\").show(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Clean-up unused variables\n# Let's try to free-up some RAM\nimport gc\ndel cv_model_lg\n# ...\n\nprint(\"Garbage collector: collected %d objects\" % (gc.collect()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv_model_lg = logistic_regression_pipeline(train_set)\n\n# Make predictions on the test set (`cv_model` contains the best model according to the result of k-fold cross validation)\n# `test_df` will follow exactly the same pipeline defined above, and already fit to `train_df`\ntest_predictions_lg = cv_model_lg.transform(test_set)\n\ntest_predictions_lg.select(\"std_features\", \"prediction\", \"label\").show(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv_model_rf = random_forest_pipeline(train_set)\n\n# Make predictions on the test set (`cv_model` contains the best model according to the result of k-fold cross validation)\n# `test_df` will follow exactly the same pipeline defined above, and already fit to `train_df`\ntest_predictions_rf = cv_model_rf.transform(test_set)\n\ntest_predictions_rf.select(\"std_features\", \"prediction\", \"label\").show(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}