{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pyspark\n!pip install findspark\n# Alternatively, if you want to install a specific version of pyspark:\n#!pip install pyspark==3.2.1 ","metadata":{"execution":{"iopub.status.busy":"2022-05-13T09:30:09.239472Z","iopub.execute_input":"2022-05-13T09:30:09.239800Z","iopub.status.idle":"2022-05-13T09:30:30.487946Z","shell.execute_reply.started":"2022-05-13T09:30:09.239769Z","shell.execute_reply":"2022-05-13T09:30:30.486843Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\nimport requests\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport pyspark\nfrom pyspark.sql import *\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import *\nfrom pyspark import SparkContext, SparkConf\nimport pyspark.sql.functions as f\nfrom pyspark.sql.functions import split, regexp_replace, year, month, dayofmonth, to_timestamp\n\nfrom pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\nfrom pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, RandomForestClassifier\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator #, BinaryClassificationEvaluator \n\n# Basic libreries \nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Pre-processing phase\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split\n\n# Features Importance\nfrom sklearn.inspection import permutation_importance\n\n# Model\nfrom sklearn import tree\nfrom sklearn import svm\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neural_network import MLPClassifier\n\n# Hyper-Parameter Tuning\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\n\nfrom sklearn.model_selection import cross_val_score\n\n# Evaluation\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report","metadata":{"execution":{"iopub.status.busy":"2022-05-13T09:30:30.490896Z","iopub.execute_input":"2022-05-13T09:30:30.491200Z","iopub.status.idle":"2022-05-13T09:30:30.513919Z","shell.execute_reply.started":"2022-05-13T09:30:30.491163Z","shell.execute_reply":"2022-05-13T09:30:30.513150Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"# Create the session\n#conf = SparkConf().set(\"spark.ui.port\", \"4050\").set('spark.executor.memory', '4G').set('spark.driver.memory', '45G').set('spark.driver.maxResultSize', '10G')\n\n# Create the context\n#sc = pyspark.SparkContext(conf=conf)\n#spark = SparkSession.builder.getOrCreate()\n\n#sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))\n#spark = SparkSession.builder.getOrCreate()\n\n#bucket = \"train_test_data_spotify\"\n#spark.conf.set('temporaryGcsBucket', bucket)\n\nspark = SparkSession \\\n    .builder \\\n    .appName(\"Python Spark Spotify Genre Model\") \\\n    .config(\"spark.some.config.option\", \"some-value\") \\\n    .getOrCreate()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T09:30:30.516315Z","iopub.execute_input":"2022-05-13T09:30:30.516595Z","iopub.status.idle":"2022-05-13T09:30:30.532558Z","shell.execute_reply.started":"2022-05-13T09:30:30.516562Z","shell.execute_reply":"2022-05-13T09:30:30.531628Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"spark","metadata":{"execution":{"iopub.status.busy":"2022-05-13T09:30:30.535090Z","iopub.execute_input":"2022-05-13T09:30:30.535427Z","iopub.status.idle":"2022-05-13T09:30:30.551354Z","shell.execute_reply.started":"2022-05-13T09:30:30.535383Z","shell.execute_reply":"2022-05-13T09:30:30.550601Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"spotify_tracks = spark.read.load(\"../input/spotify-track/dataframe.csv\", \n                           format=\"csv\", \n                           sep=\";\", \n                           inferSchema=\"true\", \n                           header=\"true\")\n","metadata":{"execution":{"iopub.status.busy":"2022-05-13T09:30:30.553944Z","iopub.execute_input":"2022-05-13T09:30:30.554203Z","iopub.status.idle":"2022-05-13T09:30:31.208411Z","shell.execute_reply.started":"2022-05-13T09:30:30.554172Z","shell.execute_reply":"2022-05-13T09:30:31.207717Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"spotify_tracks.cache()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T09:30:31.209330Z","iopub.execute_input":"2022-05-13T09:30:31.209670Z","iopub.status.idle":"2022-05-13T09:30:31.222195Z","shell.execute_reply.started":"2022-05-13T09:30:31.209626Z","shell.execute_reply":"2022-05-13T09:30:31.221188Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"print(\"The shape of the dataset is {:d} rows by {:d} columns\".format(spotify_tracks.count(), len(spotify_tracks.columns)))","metadata":{"execution":{"iopub.status.busy":"2022-05-13T09:30:31.224180Z","iopub.execute_input":"2022-05-13T09:30:31.224835Z","iopub.status.idle":"2022-05-13T09:30:31.310320Z","shell.execute_reply.started":"2022-05-13T09:30:31.224785Z","shell.execute_reply":"2022-05-13T09:30:31.309326Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"spotify_tracks.printSchema()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T09:30:31.311529Z","iopub.execute_input":"2022-05-13T09:30:31.311828Z","iopub.status.idle":"2022-05-13T09:30:31.318562Z","shell.execute_reply.started":"2022-05-13T09:30:31.311788Z","shell.execute_reply":"2022-05-13T09:30:31.317590Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"spotify_tracks.show(5)","metadata":{"execution":{"iopub.status.busy":"2022-05-13T09:30:31.320052Z","iopub.execute_input":"2022-05-13T09:30:31.320533Z","iopub.status.idle":"2022-05-13T09:30:31.438613Z","shell.execute_reply.started":"2022-05-13T09:30:31.320490Z","shell.execute_reply":"2022-05-13T09:30:31.437683Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"spotify_tracks = spotify_tracks.dropDuplicates()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T09:30:31.442658Z","iopub.execute_input":"2022-05-13T09:30:31.443346Z","iopub.status.idle":"2022-05-13T09:30:31.450215Z","shell.execute_reply.started":"2022-05-13T09:30:31.443295Z","shell.execute_reply":"2022-05-13T09:30:31.449328Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"spotify_tracks = spotify_tracks.select(spotify_tracks.columns + [f.translate(f.col(\"audio_avg_pitches\"), \"[]\", \"\").alias(\"audio_avg_pitches_list\")])\nspotify_tracks = spotify_tracks.withColumn(\"pitch_1\", split(col(\"audio_avg_pitches_list\"), \", \").getItem(0))\\\n                                .withColumn(\"pitch_2\", split(col(\"audio_avg_pitches_list\"), \", \").getItem(1))\\\n                                .withColumn(\"pitch_3\", split(col(\"audio_avg_pitches_list\"), \", \").getItem(2))\\\n                                .withColumn(\"pitch_4\", split(col(\"audio_avg_pitches_list\"), \", \").getItem(3))\\\n                                .withColumn(\"pitch_5\", split(col(\"audio_avg_pitches_list\"), \", \").getItem(4))\\\n                                .withColumn(\"pitch_6\", split(col(\"audio_avg_pitches_list\"), \", \").getItem(5))\\\n                                .withColumn(\"pitch_7\", split(col(\"audio_avg_pitches_list\"), \", \").getItem(6))\\\n                                .withColumn(\"pitch_8\", split(col(\"audio_avg_pitches_list\"), \", \").getItem(7))\\\n                                .withColumn(\"pitch_9\", split(col(\"audio_avg_pitches_list\"), \", \").getItem(8))\\\n                                .withColumn(\"pitch_10\", split(col(\"audio_avg_pitches_list\"), \", \").getItem(9))\\\n                                .withColumn(\"pitch_11\", split(col(\"audio_avg_pitches_list\"), \", \").getItem(10))\\\n                                .withColumn(\"pitch_12\", split(col(\"audio_avg_pitches_list\"), \", \").getItem(11))\nspotify_tracks.printSchema()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T09:30:31.451500Z","iopub.execute_input":"2022-05-13T09:30:31.451807Z","iopub.status.idle":"2022-05-13T09:30:31.714832Z","shell.execute_reply.started":"2022-05-13T09:30:31.451763Z","shell.execute_reply":"2022-05-13T09:30:31.713899Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"spotify_tracks = spotify_tracks.select(spotify_tracks.columns + [f.translate(f.col(\"audio_avg_timbre\"), \"[]\", \"\").alias(\"audio_avg_timbre_list\")])\nspotify_tracks = spotify_tracks.withColumn(\"timbre_1\", split(col(\"audio_avg_timbre_list\"), \", \").getItem(0))\\\n                                .withColumn(\"timbre_2\", split(col(\"audio_avg_timbre_list\"), \", \").getItem(1))\\\n                                .withColumn(\"timbre_3\", split(col(\"audio_avg_timbre_list\"), \", \").getItem(2))\\\n                                .withColumn(\"timbre_4\", split(col(\"audio_avg_timbre_list\"), \", \").getItem(3))\\\n                                .withColumn(\"timbre_5\", split(col(\"audio_avg_timbre_list\"), \", \").getItem(4))\\\n                                .withColumn(\"timbre_6\", split(col(\"audio_avg_timbre_list\"), \", \").getItem(5))\\\n                                .withColumn(\"timbre_7\", split(col(\"audio_avg_timbre_list\"), \", \").getItem(6))\\\n                                .withColumn(\"timbre_8\", split(col(\"audio_avg_timbre_list\"), \", \").getItem(7))\\\n                                .withColumn(\"timbre_9\", split(col(\"audio_avg_timbre_list\"), \", \").getItem(8))\\\n                                .withColumn(\"timbre_10\", split(col(\"audio_avg_timbre_list\"), \", \").getItem(9))\\\n                                .withColumn(\"timbre_11\", split(col(\"audio_avg_timbre_list\"), \", \").getItem(10))\\\n                                .withColumn(\"timbre_12\", split(col(\"audio_avg_timbre_list\"), \", \").getItem(11))\nspotify_tracks.printSchema()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T09:30:31.716173Z","iopub.execute_input":"2022-05-13T09:30:31.716497Z","iopub.status.idle":"2022-05-13T09:30:31.953692Z","shell.execute_reply.started":"2022-05-13T09:30:31.716455Z","shell.execute_reply":"2022-05-13T09:30:31.952420Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"# String to Date but return null value \n# spotify_tracks_dt = spotify_tracks.withColumn(\"album_release_date\", to_date(col(\"album_release_date\"),\"yyyy-MM-dd\"))\n# spotify_tracks_dt.select(\"album_release_date\").show()\n\ndef to_date_(col, formats=(\"yyyy-MM-dd\", \"y\")):\n    # Spark 2.2 or later syntax, for < 2.2 use unix_timestamp and cast\n    return coalesce(*[to_date(col, f) for f in formats])\n\nspotify_tracks = spotify_tracks.withColumn(\"album_release_date_td\", to_date_(\"album_release_date\"))\nspotify_tracks.select(\"album_release_date_td\").show()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T09:30:31.955349Z","iopub.execute_input":"2022-05-13T09:30:31.955662Z","iopub.status.idle":"2022-05-13T09:30:32.831056Z","shell.execute_reply.started":"2022-05-13T09:30:31.955619Z","shell.execute_reply":"2022-05-13T09:30:32.830415Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"spotify_tracks = spotify_tracks.withColumn('day', dayofmonth(col('album_release_date_td')))\nspotify_tracks = spotify_tracks.withColumn('month', month(col('album_release_date_td')))\nspotify_tracks = spotify_tracks.withColumn('year', year(col('album_release_date_td')))","metadata":{"execution":{"iopub.status.busy":"2022-05-13T09:30:32.831956Z","iopub.execute_input":"2022-05-13T09:30:32.832151Z","iopub.status.idle":"2022-05-13T09:30:32.885118Z","shell.execute_reply.started":"2022-05-13T09:30:32.832125Z","shell.execute_reply":"2022-05-13T09:30:32.884443Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"spotify_tracks.printSchema()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T09:30:32.886000Z","iopub.execute_input":"2022-05-13T09:30:32.886202Z","iopub.status.idle":"2022-05-13T09:30:32.892962Z","shell.execute_reply.started":"2022-05-13T09:30:32.886176Z","shell.execute_reply":"2022-05-13T09:30:32.892006Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"cols = (\"album_release_date\", \"album_release_date_td\", \"audio_avg_pitches\",\"audio_avg_timbre\", \"audio_avg_pitches_list\", \"audio_avg_timbre_list\", \"track_uri\", \"id\")\nspotify_tracks = spotify_tracks.drop(*cols)\n\nspotify_tracks.printSchema()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T09:30:32.894644Z","iopub.execute_input":"2022-05-13T09:30:32.894972Z","iopub.status.idle":"2022-05-13T09:30:32.920186Z","shell.execute_reply.started":"2022-05-13T09:30:32.894929Z","shell.execute_reply":"2022-05-13T09:30:32.919298Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"spotify_tracks = spotify_tracks.withColumn(\"pitch_1\", spotify_tracks.pitch_1.cast('double'))\\\n                                .withColumn(\"pitch_2\", spotify_tracks.pitch_2.cast('double'))\\\n                                .withColumn(\"pitch_3\", spotify_tracks.pitch_3.cast('double'))\\\n                                .withColumn(\"pitch_4\", spotify_tracks.pitch_4.cast('double'))\\\n                                .withColumn(\"pitch_5\", spotify_tracks.pitch_5.cast('double'))\\\n                                .withColumn(\"pitch_6\", spotify_tracks.pitch_6.cast('double'))\\\n                                .withColumn(\"pitch_7\", spotify_tracks.pitch_7.cast('double'))\\\n                                .withColumn(\"pitch_8\", spotify_tracks.pitch_8.cast('double'))\\\n                                .withColumn(\"pitch_9\", spotify_tracks.pitch_9.cast('double'))\\\n                                .withColumn(\"pitch_10\", spotify_tracks.pitch_10.cast('double'))\\\n                                .withColumn(\"pitch_11\", spotify_tracks.pitch_11.cast('double'))\\\n                                .withColumn(\"pitch_12\", spotify_tracks.pitch_12.cast('double'))\n\nspotify_tracks = spotify_tracks.withColumn(\"timbre_1\", spotify_tracks.timbre_1.cast('double'))\\\n                                .withColumn(\"timbre_2\", spotify_tracks.timbre_2.cast('double'))\\\n                                .withColumn(\"timbre_3\", spotify_tracks.timbre_3.cast('double'))\\\n                                .withColumn(\"timbre_4\", spotify_tracks.timbre_4.cast('double'))\\\n                                .withColumn(\"timbre_5\", spotify_tracks.timbre_5.cast('double'))\\\n                                .withColumn(\"timbre_6\", spotify_tracks.timbre_6.cast('double'))\\\n                                .withColumn(\"timbre_7\", spotify_tracks.timbre_7.cast('double'))\\\n                                .withColumn(\"timbre_8\", spotify_tracks.timbre_8.cast('double'))\\\n                                .withColumn(\"timbre_9\", spotify_tracks.timbre_9.cast('double'))\\\n                                .withColumn(\"timbre_10\", spotify_tracks.timbre_10.cast('double'))\\\n                                .withColumn(\"timbre_11\", spotify_tracks.timbre_11.cast('double'))\\\n                                .withColumn(\"timbre_12\", spotify_tracks.timbre_12.cast('double'))\n\nspotify_tracks = spotify_tracks.withColumn(\"year\", spotify_tracks.year.cast('int'))\\\n                                .withColumn(\"day\", spotify_tracks.day.cast('int'))\\\n                                .withColumn(\"month\", spotify_tracks.month.cast('int'))\n\nspotify_tracks.printSchema()\n","metadata":{"execution":{"iopub.status.busy":"2022-05-13T09:30:32.921491Z","iopub.execute_input":"2022-05-13T09:30:32.922719Z","iopub.status.idle":"2022-05-13T09:30:33.328331Z","shell.execute_reply.started":"2022-05-13T09:30:32.922670Z","shell.execute_reply":"2022-05-13T09:30:33.327324Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"# Let's define some constants which we will use throughout this notebook\nNUMERICAL_FEATURES = []\nCATEGORICAL_FEATURES = []\nTARGET_VARIABLE = \"track_genre\"\n\n#Get All column names and it's types\nfor col in spotify_tracks.dtypes:\n    if col[1] == \"string\":\n        CATEGORICAL_FEATURES.append(col[0])\n    else:\n        NUMERICAL_FEATURES.append(col[0])\n\nCATEGORICAL_FEATURES.remove(TARGET_VARIABLE)\nprint(\"Categorical: \", CATEGORICAL_FEATURES, \"\\nNumerical: \", NUMERICAL_FEATURES)","metadata":{"execution":{"iopub.status.busy":"2022-05-13T09:30:33.329598Z","iopub.execute_input":"2022-05-13T09:30:33.329885Z","iopub.status.idle":"2022-05-13T09:30:33.340934Z","shell.execute_reply.started":"2022-05-13T09:30:33.329846Z","shell.execute_reply":"2022-05-13T09:30:33.340086Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"spotify_tracks.cache()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T09:30:33.342517Z","iopub.execute_input":"2022-05-13T09:30:33.343319Z","iopub.status.idle":"2022-05-13T09:30:33.371580Z","shell.execute_reply.started":"2022-05-13T09:30:33.343270Z","shell.execute_reply":"2022-05-13T09:30:33.370699Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"#spotify_tracks_rp = spark.createDataFrame(spotify_tracks_pd)\n\nspotify_tracks.rdd.getNumPartitions()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T09:30:33.373163Z","iopub.execute_input":"2022-05-13T09:30:33.374106Z","iopub.status.idle":"2022-05-13T09:30:33.428885Z","shell.execute_reply.started":"2022-05-13T09:30:33.374060Z","shell.execute_reply":"2022-05-13T09:30:33.427959Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"#spotify_tracks = spotify_tracks.repartition(6)\n##spotify_tracks = spotify_tracks_rp.coalesce(1)","metadata":{"execution":{"iopub.status.busy":"2022-05-13T09:30:33.431445Z","iopub.execute_input":"2022-05-13T09:30:33.431796Z","iopub.status.idle":"2022-05-13T09:30:33.436137Z","shell.execute_reply.started":"2022-05-13T09:30:33.431745Z","shell.execute_reply":"2022-05-13T09:30:33.435279Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"#spotify_tracks.rdd.getNumPartitions()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T09:30:33.437046Z","iopub.execute_input":"2022-05-13T09:30:33.437383Z","iopub.status.idle":"2022-05-13T09:30:33.451577Z","shell.execute_reply.started":"2022-05-13T09:30:33.437354Z","shell.execute_reply":"2022-05-13T09:30:33.450668Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"# null values in each column\nspark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")\ndata_agg = spotify_tracks.agg(*[f.count(f.when(f.isnull(c), c)).alias(c) for c in spotify_tracks.columns])\n\ndata_agg.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T09:30:33.454985Z","iopub.execute_input":"2022-05-13T09:30:33.455607Z","iopub.status.idle":"2022-05-13T09:30:34.822563Z","shell.execute_reply.started":"2022-05-13T09:30:33.455569Z","shell.execute_reply":"2022-05-13T09:30:34.821610Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"spotify_tracks = spotify_tracks.dropna()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T09:30:34.823852Z","iopub.execute_input":"2022-05-13T09:30:34.824187Z","iopub.status.idle":"2022-05-13T09:30:34.857364Z","shell.execute_reply.started":"2022-05-13T09:30:34.824133Z","shell.execute_reply":"2022-05-13T09:30:34.856349Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"data_agg = spotify_tracks.agg(*[f.count(f.when(f.isnull(c), c)).alias(c) for c in spotify_tracks.columns])\n\ndata_agg.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T09:30:34.858667Z","iopub.execute_input":"2022-05-13T09:30:34.858991Z","iopub.status.idle":"2022-05-13T09:30:36.530213Z","shell.execute_reply.started":"2022-05-13T09:30:34.858949Z","shell.execute_reply":"2022-05-13T09:30:36.529183Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"# value counts of Batsman_Name column\nspotify_tracks.groupBy('album_release_date_precision').count().show()\n\nspotify_tracks.groupBy('track_name').count().show()\n\nspotify_tracks.groupBy('album_name').count().show()\n\nspotify_tracks.groupBy('artist_name').count().show()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T09:30:36.531469Z","iopub.execute_input":"2022-05-13T09:30:36.531771Z","iopub.status.idle":"2022-05-13T09:30:53.016888Z","shell.execute_reply.started":"2022-05-13T09:30:36.531731Z","shell.execute_reply":"2022-05-13T09:30:53.015358Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"# This function is responsible to implement the pipeline above for transforming categorical features into numerical ones\ndef to_numerical(df, numerical_features, categorical_features, target_variable):\n  \n    # 1. Label Encode target feature \n    stage_1= StringIndexer(inputCol=target_variable, outputCol='label')\n\n    # 2. Label Encode Categorical features\n    stage_2 = [StringIndexer(inputCol=c, outputCol=\"{0}_index\".format(c), handleInvalid=\"skip\") for c in categorical_features]\n\n    # 3. OneHot Encode \n    # stage_3 = OneHotEncoder(inputCol='album_release_date_precision_index', outputCol='album_release_date_precision_oh')\n\n    # 4. create a vector of all the features required to train the logistic regression model \n    # encoded_columns = ['track_name_index', 'album_name_index', 'artist_name_index', 'album_release_date_precision_oh']\n    # stage_4 = VectorAssembler(inputCols= encoded_columns + numerical_features, outputCol='features')\n    stage_4 = VectorAssembler(inputCols= [indexer.getOutputCol() for indexer in stage_2] + numerical_features, outputCol='features')\n\n    # 4.a Create the StandardScaler\n    scaler = StandardScaler(inputCol=stage_4.getOutputCol(), outputCol=\"std_\" + stage_4.getOutputCol(), withStd=True, withMean=True)\n\n    # 5. Populate the stages of the pipeline\n    # stages = [stage_1] + stage_2 +[stage_3] + [stage_4] + [scaler]\n    stages = [stage_1] + stage_2 + [stage_4] + [scaler]\n\n    # 6. Setup the pipeline with the stages above\n    pipeline = Pipeline(stages=stages)\n\n    # 7. Transform the input dataframe accordingly\n    transformer = pipeline.fit(df)\n    df_transformed = transformer.transform(df)\n\n    return df_transformed","metadata":{"execution":{"iopub.status.busy":"2022-05-13T09:30:53.018856Z","iopub.execute_input":"2022-05-13T09:30:53.019177Z","iopub.status.idle":"2022-05-13T09:30:53.036343Z","shell.execute_reply.started":"2022-05-13T09:30:53.019131Z","shell.execute_reply":"2022-05-13T09:30:53.032816Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"# Transform the training set and get back both the transformer and the new dataset\nspotify_tracks = to_numerical(spotify_tracks, NUMERICAL_FEATURES, CATEGORICAL_FEATURES, TARGET_VARIABLE)\nspotify_tracks.cache()\n\n# Select `features` and `label` (i.e., formerly `deposit`) target variable only\nspotify_tracks = spotify_tracks.select([\"features\", \"label\"])\nspotify_tracks.cache()\n\nRANDOM_SEED = 42\n# Randomly split our original dataset `house_df` into 80÷20 for training and test, respectively\ntrain_set, test_set = spotify_tracks.randomSplit([0.8, 0.2], seed=RANDOM_SEED)\n\ntrain_set.show(5, truncate=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-13T09:30:53.045648Z","iopub.execute_input":"2022-05-13T09:30:53.046299Z","iopub.status.idle":"2022-05-13T09:31:38.348784Z","shell.execute_reply.started":"2022-05-13T09:30:53.046193Z","shell.execute_reply":"2022-05-13T09:31:38.347827Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"# This function defines the general pipeline for logistic regression\ndef logistic_regression_pipeline(train):\n  \n    stage_5_lg = LogisticRegression(featuresCol='features',labelCol='label')\n\n    logistic_regression_pipeline = Pipeline(stages= [stage_5_lg])\n\n    #### LOGISTIC REGRESSION\n    param_grid = ParamGridBuilder()\\\n    .addGrid(stage_5_lg.regParam, [0.01, 0.1, 1.0]) \\\n    .addGrid(stage_5_lg.maxIter, [10, 20, 50]) \\\n    .build()\n    # other param: .addGrid(stage_4_lg.elasticNetParam, [0.0, 0.25, 0.5, 0.75, 1.0])\n    cross_val_lg = CrossValidator(estimator=logistic_regression_pipeline,\n                            estimatorParamMaps=param_grid,\n                            evaluator=MulticlassClassificationEvaluator().setMetricName(\"accuracy\"), # default = \"areaUnderROC\", alternatively \"areaUnderPR\"\n                            numFolds=5,\n                            collectSubModels=True\n                            )\n    cv_model_lg = cross_val_lg.fit(spotify_tracks)\n\n    return cv_model_lg","metadata":{"execution":{"iopub.status.busy":"2022-05-13T09:31:38.349962Z","iopub.execute_input":"2022-05-13T09:31:38.350256Z","iopub.status.idle":"2022-05-13T09:31:38.370661Z","shell.execute_reply.started":"2022-05-13T09:31:38.350203Z","shell.execute_reply":"2022-05-13T09:31:38.369716Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"cv_model = logistic_regression_pipeline(train_set)\n\n# Make predictions on the test set (`cv_model` contains the best model according to the result of k-fold cross validation)\n# `test_df` will follow exactly the same pipeline defined above, and already fit to `train_df`\ntest_predictions = cv_model.transform(test_set)\n\ntest_predictions.select(\"features\", \"prediction\", \"label\").show(5)","metadata":{"execution":{"iopub.status.busy":"2022-05-13T09:31:38.372886Z","iopub.execute_input":"2022-05-13T09:31:38.373517Z"},"trusted":true},"execution_count":null,"outputs":[]}]}